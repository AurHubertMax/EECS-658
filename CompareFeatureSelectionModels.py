# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/154lEPfRdesoJO_k9ohB_UHIRCjYnx1sF
"""

'''
  Name of program: CompareFeatureSelectionModels
  Author: Aureliano Hubert Maximus
  Creation Date: Oct 12 2023
  Description:
    this program completes part 1 and 2 for EECS 658 Assignment 4
  Collaborators:
  Prof. David Johnson (EECS 658 Slides)
  ChatGPT
  '''

from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.datasets import load_iris
from sklearn import datasets
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.preprocessing import LabelEncoder
from sklearn import preprocessing
from sklearn.preprocessing import PolynomialFeatures
import numpy as np

# Part 1

#load datasets
url = "iris.csv"
names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']
dataset = read_csv(url, names=names)

array = dataset.values
X = array[:,0:4]
Y = array[:,4]

#load encoder
encoder = preprocessing.LabelEncoder()
encoder.fit(Y)
X_Fold1, X_Fold2, Y_Fold1, Y_Fold2 = train_test_split(X, Y, test_size=0.50, random_state=1)

#select model
model = DecisionTreeClassifier()
model.fit(X_Fold1, Y_Fold1)
pred1 = model.predict(X_Fold2)
model.fit(X_Fold2, Y_Fold2)
pred2 = model.predict(X_Fold1)
actual = np.concatenate([Y_Fold2, Y_Fold1])
predicted = np.concatenate([pred1, pred2])

#print the original 4 features accuracy score and confusion matrix
print("Part 1: Original 4 features")
print('Accuracy Score: ' + str(accuracy_score(actual, predicted)))
print('Confusion Matrix: ')
print(confusion_matrix(actual, predicted))
print("Features: ['sepal-length', 'sepal-width', 'petal-length', 'petal-width']\n")



# Part 2
print("Part 2: PCA")

#transform features into z1, z2, z3, z4
pca = PCA(n_components=4)
pca.fit(X)

#calculate eigenvector and eigenvalues
eigenvector = pca.components_
eigenvalues = pca.explained_variance_

principleComponents = pca.transform(X)

sumvariance = np.cumsum(eigenvalues)
sumvariance /= sumvariance[-1]

#prints out the eigenvector and eigenvalues
print("Eigenvalues:")
print(eigenvalues)
print("Eigenvectors:")
print(eigenvector)

eigen_pairs = list(zip(eigenvalues, eigenvector))
eigen_pairs.sort(key=lambda x: x[0], reverse=True)

W = eigen_pairs[0][1].reshape(4,1)
Z = principleComponents.dot(W)

#print out the PoV
print("PoV: ", eigenvalues[0]/np.sum(eigenvalues))

#selected z1
Z = principleComponents[:, 0].reshape(-1, 1)
#trains and predicts new folds
X_Fold1_z1, X_Fold2_z1, Y_Fold1_z1, Y_Fold2_z1 = train_test_split(Z, Y, test_size=0.50, random_state=1)
modelz1 = DecisionTreeClassifier() #select model
modelz1.fit(X_Fold1_z1, Y_Fold1_z1)
pred1z1 = modelZ.predict(X_Fold2_z1)
modelz1.fit(X_Fold2_z1, Y_Fold2_z1)
pred2z1 = modelZ.predict(X_Fold1_z1)
actualz1 = np.concatenate([Y_Fold2_z1, Y_Fold1_z1])
predictedz1 = np.concatenate([pred1z1, pred2z1])

#prints the results
print('model: Decision Tree')
print('Accuracy Score: ' + str(accuracy_score(actualZ, predictedZ)))
print('Confusion Matrix: ')
print(confusion_matrix(actualZ, predictedZ))